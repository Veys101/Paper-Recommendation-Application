{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Author1</th>\n",
       "      <th>Author2</th>\n",
       "      <th>textLink</th>\n",
       "      <th>pdfLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1802.00209v1</td>\n",
       "      <td>2</td>\n",
       "      <td>We propose an architecture for VQA which utili...</td>\n",
       "      <td>Dual Recurrent Attention Units for Visual Ques...</td>\n",
       "      <td>2018</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>Ahmed Osman</td>\n",
       "      <td>Wojciech Samek</td>\n",
       "      <td>http://arxiv.org/abs/1802.00209v1</td>\n",
       "      <td>http://arxiv.org/pdf/1802.00209v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1603.03827v1</td>\n",
       "      <td>3</td>\n",
       "      <td>Recent approaches based on artificial neural n...</td>\n",
       "      <td>Sequential Short-Text Classification with Recu...</td>\n",
       "      <td>2016</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Ji Young Lee</td>\n",
       "      <td>Franck Dernoncourt</td>\n",
       "      <td>http://arxiv.org/abs/1603.03827v1</td>\n",
       "      <td>http://arxiv.org/pdf/1603.03827v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1606.00776v2</td>\n",
       "      <td>6</td>\n",
       "      <td>We introduce the multiresolution recurrent neu...</td>\n",
       "      <td>Multiresolution Recurrent Neural Networks: An ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Iulian Vlad Serban</td>\n",
       "      <td>Tim Klinger</td>\n",
       "      <td>http://arxiv.org/abs/1606.00776v2</td>\n",
       "      <td>http://arxiv.org/pdf/1606.00776v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>1705.08142v2</td>\n",
       "      <td>5</td>\n",
       "      <td>Multi-task learning is motivated by the observ...</td>\n",
       "      <td>Learning what to share between loosely related...</td>\n",
       "      <td>2017</td>\n",
       "      <td>stat.ML</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>Sebastian Ruder</td>\n",
       "      <td>Joachim Bingel</td>\n",
       "      <td>http://arxiv.org/abs/1705.08142v2</td>\n",
       "      <td>http://arxiv.org/pdf/1705.08142v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1709.02349v2</td>\n",
       "      <td>9</td>\n",
       "      <td>We present MILABOT: a deep reinforcement learn...</td>\n",
       "      <td>A Deep Reinforcement Learning Chatbot</td>\n",
       "      <td>2017</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Iulian V. Serban</td>\n",
       "      <td>Chinnadhurai Sankar</td>\n",
       "      <td>http://arxiv.org/abs/1709.02349v2</td>\n",
       "      <td>http://arxiv.org/pdf/1709.02349v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day            id  month  \\\n",
       "0    1  1802.00209v1      2   \n",
       "1   12  1603.03827v1      3   \n",
       "2    2  1606.00776v2      6   \n",
       "3   23  1705.08142v2      5   \n",
       "4    7  1709.02349v2      9   \n",
       "\n",
       "                                             summary  \\\n",
       "0  We propose an architecture for VQA which utili...   \n",
       "1  Recent approaches based on artificial neural n...   \n",
       "2  We introduce the multiresolution recurrent neu...   \n",
       "3  Multi-task learning is motivated by the observ...   \n",
       "4  We present MILABOT: a deep reinforcement learn...   \n",
       "\n",
       "                                               title  year   Topic1 Topic2  \\\n",
       "0  Dual Recurrent Attention Units for Visual Ques...  2018    cs.AI  cs.CL   \n",
       "1  Sequential Short-Text Classification with Recu...  2016    cs.CL  cs.AI   \n",
       "2  Multiresolution Recurrent Neural Networks: An ...  2016    cs.CL  cs.AI   \n",
       "3  Learning what to share between loosely related...  2017  stat.ML  cs.AI   \n",
       "4              A Deep Reinforcement Learning Chatbot  2017    cs.CL  cs.AI   \n",
       "\n",
       "  Topic3             Author1              Author2  \\\n",
       "0  cs.CV         Ahmed Osman       Wojciech Samek   \n",
       "1  cs.LG        Ji Young Lee   Franck Dernoncourt   \n",
       "2  cs.LG  Iulian Vlad Serban          Tim Klinger   \n",
       "3  cs.CL     Sebastian Ruder       Joachim Bingel   \n",
       "4  cs.LG    Iulian V. Serban  Chinnadhurai Sankar   \n",
       "\n",
       "                             textLink                             pdfLink  \n",
       "0   http://arxiv.org/abs/1802.00209v1   http://arxiv.org/pdf/1802.00209v1  \n",
       "1   http://arxiv.org/abs/1603.03827v1   http://arxiv.org/pdf/1603.03827v1  \n",
       "2   http://arxiv.org/abs/1606.00776v2   http://arxiv.org/pdf/1606.00776v2  \n",
       "3   http://arxiv.org/abs/1705.08142v2   http://arxiv.org/pdf/1705.08142v2  \n",
       "4   http://arxiv.org/abs/1709.02349v2   http://arxiv.org/pdf/1709.02349v2  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#papers_df is pandas dataframe object\n",
    "papers_df = pd.read_json('temp4.json', lines=True)\n",
    "\n",
    "papers_df.head()\n",
    "\n",
    "#papers_df = pd.read_json('NIP_DataSet/papers_2K.json',lines=True)\n",
    "papers_df.rename(columns = {\"paper_text\" : \"summary\"},inplace=True)\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get papers metadata from mongodb\n",
    "\n",
    "#from pymongo import MongoClient\n",
    "#client = MongoClient('mongodb://localhost:27017')\n",
    "#db = client['Paper']\n",
    "#collection = db['Papers']\n",
    "#data = collection.find({})\n",
    "#data_list = list(data)\n",
    "#papers_df = pd.DataFrame(data_list)\n",
    "#papers_df.drop(columns=['_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers_df['title'] = papers_df['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of conversing with humans on popular small talk\\ntopics through both speech and text. The system consists of an ensemble of\\nnatural language generation and retrieval models, including template-based\\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\\nvariable neural network models. By applying reinforcement learning to\\ncrowdsourced data and real-world user interactions, the system has been trained\\nto select an appropriate response from the models in its ensemble. The system\\nhas been evaluated through A/B testing with real-world users, where it\\nperformed significantly better than many competing systems. Due to its machine\\nlearning architecture, the system is likely to improve with additional data.'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df['summary'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df['summary'] = papers_df['summary'].str.replace('[{}]'.format(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df['summary'] = papers_df['summary'].str.replace('\\d+|\\n+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df['summary'] = papers_df['summary'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "#englishStemmer=SnowballStemmer(\"english\") #define stemming dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def stemm_texts(text):\n",
    "#   return [englishStemmer.stem(w) for w in w_tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers_df['summary'] = papers_df.summary.apply(stemm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We present MILABOT a deep reinforcement learning chatbot developed by theMontreal Institute for Learning Algorithms MILA for the Amazon Alexa Prizecompetition MILABOT is capable of conversing with humans on popular small talktopics through both speech and text The system consists of an ensemble ofnatural language generation and retrieval models including templatebasedmodels bagofwords models sequencetosequence neural network and latentvariable neural network models By applying reinforcement learning tocrowdsourced data and realworld user interactions the system has been trainedto select an appropriate response from the models in its ensemble The systemhas been evaluated through AB testing with realworld users where itperformed significantly better than many competing systems Due to its machinelearning architecture the system is likely to improve with additional data'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df['summary'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers :  (8000, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Papers : \", papers_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   day       8000 non-null   int64 \n",
      " 1   id        8000 non-null   object\n",
      " 2   month     8000 non-null   int64 \n",
      " 3   summary   8000 non-null   object\n",
      " 4   title     8000 non-null   object\n",
      " 5   year      8000 non-null   int64 \n",
      " 6   Topic1    8000 non-null   object\n",
      " 7   Topic2    8000 non-null   object\n",
      " 8   Topic3    4319 non-null   object\n",
      " 9   Author1   8000 non-null   object\n",
      " 10  Author2   8000 non-null   object\n",
      " 11  textLink  8000 non-null   object\n",
      " 12  pdfLink   8000 non-null   object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "papers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cs/0204043v1'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.iloc[757].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse mapping of indices and paper titles\n",
    "indices = pd.Series(papers_df.index, index=papers_df['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Dual Recurrent Attention Units for Visual Question Answering                                      0\n",
       "Sequential Short-Text Classification with Recurrent and Convolutional  Neural Networks            1\n",
       "Multiresolution Recurrent Neural Networks: An Application to Dialogue  Response Generation        2\n",
       "Learning what to share between loosely related tasks                                              3\n",
       "A Deep Reinforcement Learning Chatbot                                                             4\n",
       "                                                                                               ... \n",
       "BreathRNNet: Breathing Based Authentication on Resource-Constrained IoT  Devices using RNNs    7995\n",
       "Deep Learning applied to Road Traffic Speed forecasting                                        7996\n",
       "ChainerMN: Scalable Distributed Deep Learning Framework                                        7997\n",
       "Minimum Energy Quantized Neural Networks                                                       7998\n",
       "Performance Evaluation of Channel Decoding With Deep Neural Networks                           7999\n",
       "Length: 8000, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = indices['Semi-Supervised Learning with Ladder Networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{3,}',\n",
    "            ngram_range=(1, 3),\n",
    "            stop_words = 'english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df['all_content'] = papers_df['title']+papers_df['summary']\n",
    "#anahtar kelime, tag, tarih(son 5 yÄ±l )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv_matrix = tfv.fit_transform(papers_df['all_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1266511)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function helps to find the most similar papers to specified paper.\n",
    "def calc_similarity(method_name):\n",
    "    \n",
    "    if method_name == 'sigmoid_kernel':\n",
    "        matrix = sigmoid_kernel(tfv_matrix, tfv_matrix,gamma = 0.8, coef0=0.5)\n",
    "    elif method_name == 'linear_kernel':\n",
    "        matrix = linear_kernel(tfv_matrix, tfv_matrix)\n",
    "    elif method_name == 'euclidean_distances':\n",
    "        matrix = euclidean_distances(tfv_matrix)\n",
    "    elif method_name == 'cosine_similarity':\n",
    "        matrix = cosine_similarity(tfv_matrix,tfv_matrix)\n",
    "    elif method_name == 'pearsons_correlation':\n",
    "        tfv_array = tfv_matrix.toarray()\n",
    "        matrix = []\n",
    "        for i in range(len(tfv_array)):\n",
    "             matrix.append(pearsonr(tfv_array[ind], tfv_array[i])[0])\n",
    "        \n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = calc_similarity('cosine_similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_rec(title, matrix=matrix):\n",
    "    # Get the index corresponding to title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores \n",
    "    sig_scores = list(enumerate(matrix[idx]))\n",
    "\n",
    "    # Sort the paper \n",
    "    sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Scores of the 10 most similar papers\n",
    "    sig_scores = sig_scores[1:11]\n",
    "    \n",
    "    data = []\n",
    "    count = 0\n",
    "    while count<10:\n",
    "        data.append([(papers_df.iloc[sig_scores[count][0]].id),(papers_df['title'].iloc[sig_scores[count][0]]), sig_scores[count][1]])\n",
    "        count=count+1\n",
    "\n",
    "    df = pd.DataFrame(data, columns = [\"id\", \"title\", \"score\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1504.08215v1</td>\n",
       "      <td>Lateral Connections in Denoising Autoencoders ...</td>\n",
       "      <td>0.112891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1611.02320v1</td>\n",
       "      <td>Adversarial Ladder Networks</td>\n",
       "      <td>0.054119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1711.07476v2</td>\n",
       "      <td>Virtual Adversarial Ladder Networks For Semi-s...</td>\n",
       "      <td>0.049742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1706.02124v2</td>\n",
       "      <td>Semi-Supervised Phoneme Recognition with Recur...</td>\n",
       "      <td>0.048963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1707.09219v4</td>\n",
       "      <td>Recurrent Ladder Networks</td>\n",
       "      <td>0.046477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1612.09030v2</td>\n",
       "      <td>Meta-Unsupervised-Learning: A supervised appro...</td>\n",
       "      <td>0.040736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1612.01942v1</td>\n",
       "      <td>Semi-Supervised Learning with the Deep Renderi...</td>\n",
       "      <td>0.038456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1711.04313v1</td>\n",
       "      <td>Semi-Supervised Learning via New Deep Network ...</td>\n",
       "      <td>0.036589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1210.5840v1</td>\n",
       "      <td>Supervised Learning with Similarity Functions</td>\n",
       "      <td>0.034717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1612.01756v3</td>\n",
       "      <td>Video Ladder Networks</td>\n",
       "      <td>0.031929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title     score\n",
       "0  1504.08215v1  Lateral Connections in Denoising Autoencoders ...  0.112891\n",
       "1  1611.02320v1                        Adversarial Ladder Networks  0.054119\n",
       "2  1711.07476v2  Virtual Adversarial Ladder Networks For Semi-s...  0.049742\n",
       "3  1706.02124v2  Semi-Supervised Phoneme Recognition with Recur...  0.048963\n",
       "4  1707.09219v4                          Recurrent Ladder Networks  0.046477\n",
       "5  1612.09030v2  Meta-Unsupervised-Learning: A supervised appro...  0.040736\n",
       "6  1612.01942v1  Semi-Supervised Learning with the Deep Renderi...  0.038456\n",
       "7  1711.04313v1  Semi-Supervised Learning via New Deep Network ...  0.036589\n",
       "8   1210.5840v1      Supervised Learning with Similarity Functions  0.034717\n",
       "9  1612.01756v3                              Video Ladder Networks  0.031929"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing our content-based recommendation system with Genetic Algorithms and its use with back-propagation network\n",
    "\n",
    "#str = 'Multiresolution Recurrent Neural Networks: An Application To Dialogue Response Generation'\n",
    "give_rec('Semi-Supervised Learning with Ladder Networks').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.691247463226318\n"
     ]
    }
   ],
   "source": [
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
